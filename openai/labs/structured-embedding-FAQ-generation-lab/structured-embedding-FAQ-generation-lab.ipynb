{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import openai\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from num2words import num2words\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "RESOURCE_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2022-12-01\"\n",
    "print(openai.api_base)\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\"\n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    print(s)\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTextOpenAI(prompt):\n",
    "    response = openai.Completion.create(engine=\"davinchi-003\", prompt=prompt, max_tokens=1024)\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/openning bank account.txt\", \"r\") as file:\n",
    "    doc = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FAQ Example\n",
    "\n",
    "prompt = f\"\"\"\n",
    "            {normalize_text(doc)}\n",
    "            divide the text into sections and put it in json format with a list of dictionaries with the following format:\n",
    "            [\n",
    "                {{\"<section 1 title>\":\"<the text of section 1>\"}},\n",
    "                {{\"<section 2 title>\":\"<the text of section 2>\"}}\n",
    "            ]\n",
    "            \"\"\"\n",
    "print(prompt)    \n",
    "text = generateTextOpenAI(prompt=prompt) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "sections = json.loads(normalize_text(text))\n",
    "pprint(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAQs = []\n",
    "for i in sections:\n",
    "    content = list(i.values())[0]\n",
    "    prompt = f\"\"\"\n",
    "        {content}\n",
    "        \n",
    "        generate FAQ questions and answers into json text with the following format (write only the json text):\n",
    "        [\n",
    "            {{\"<question 1>\":\"<answer 1>\"}},\n",
    "            {{\"<question 2>\":\"<answer 2>\"}}\n",
    "        ]\n",
    "    \"\"\"\n",
    "    print(prompt)\n",
    "    text = generateTextOpenAI(prompt=prompt)\n",
    "    try:\n",
    "        FAQ_dict = json.loads(normalize_text(text))\n",
    "        FAQs.append({list(i.keys())[0]: FAQ_dict})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error in parsing the json text\")\n",
    "\n",
    "pprint(FAQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "for FAQ in FAQs:\n",
    "    print(list(FAQ.keys())[0])\n",
    "    for i in list(FAQ.values())[0]:\n",
    "        print(\"\")\n",
    "        print(f\"question: {list(i.keys())[0]}\")\n",
    "        print(f\"answer:   {list(i.values())[0]}\")\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "966109304b06f24475972beef482557bb5471614be91d127d43959966e034004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
