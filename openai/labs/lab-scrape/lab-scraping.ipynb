{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import openai\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from transformers import GPT2TokenizerFast\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from IPython.core.display import display\n",
    "\n",
    "\n",
    "\n",
    "API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "RESOURCE_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\") # https://example-endpoint.openai.azure.com - for direct openAI\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2022-12-01\"\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\"\n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selenium_url = 'https://www.adidas.com/us/samba-vegan-x-disney-mickey-shoes/GY1889.html'\n",
    "# selenium_url = \"https://www.amazon.com/Redragon-S101-Keyboard-Ergonomic-Programmable/dp/B00NLZUM36/ref=sr_1_1_sspa?keywords=gaming+keyboard&pd_rd_r=0aca389c-dc43-43c8-a79c-bbf8c422e270&pd_rd_w=o70iX&pd_rd_wg=OLv4Z&pf_rd_p=12129333-2117-4490-9c17-6d31baf0582a&pf_rd_r=VJFQ47GKGSWP1G2RXENN&qid=1682795029&sr=8-1-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExRUgyR09EUTQzV1cmZW5jcnlwdGVkSWQ9QTAyNjcwNTUyNDdUN09aTjgwVzNCJmVuY3J5cHRlZEFkSWQ9QTA3ODkwNjYyMlpIUUM2VEpJV0RGJndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(selenium_url)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "display(soup.prettify())\n",
    "display(\"********************************************************\")\n",
    "scripts = soup.find_all('script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in scripts:\n",
    "    # print(f\"len(script.text)={len(script.text)}\")\n",
    "    # n_tokens = len(tokenizer.encode(script.text))\n",
    "    # print(f\"n_tokens={n_tokens}\")\n",
    "    print(\"************************input text********************************\")\n",
    "    print(script.text)\n",
    "    prompt = f\"\"\"You are a website scrapper that is looking for products and prices in scripts in html. \n",
    "    find the products and details about the products (sizes, colors, etc...) and price. when you find a product, create a dictionaries with the following format:\n",
    "\n",
    "    {{\n",
    "        \"products\": [\n",
    "            {{\n",
    "                \"product\" {{\n",
    "                    \"product name\": <product name>,\n",
    "                    \"product price\": <product price>,\n",
    "                    \"product category\": <product category such as shoes, jackets, etc...>,\n",
    "                    \"product details\": {{\n",
    "                        \"size\": <product sizes options>,\n",
    "                        \"color\": <product color>,\n",
    "                        etc...\n",
    "                    }}\n",
    "                }},\n",
    "                ...\n",
    "            }}\n",
    "        ],\n",
    "        \"python code\": <here put a python script that will generate the \"product\" dict above. the python code should be a function called parse_product(text) that returns the \"products\" list>\n",
    "        \n",
    "    }}\n",
    "    Mention if any of the details affect the price of the product. if there is no products in the text, put an empty list in the products field and an empty string in the python code value.\n",
    "    find in the following script: \n",
    "    {script.text}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(engine=\"davinchi-003\", prompt=prompt, max_tokens=1024)\n",
    "        # response = openai.ChatCompletion.create(\n",
    "        #     engine=\"gpt-35-turbo\",\n",
    "        #     messages = [\n",
    "        #             {\"role\": \"system\", \"content\": \"you are a website scrapper that is looking for products and prices in scripts in html. find the products and details about the products (sizes, colors, etc...) and price. when you find a product, create a dictionaries with the following format:\"},\n",
    "        #             {\"role\": \"user\", \"content\": script.text}\n",
    "        #         ],\n",
    "        #     temperature=0.7,\n",
    "        #     max_tokens=800,\n",
    "        #     top_p=0.95,\n",
    "        #     frequency_penalty=0,\n",
    "        #     presence_penalty=0,\n",
    "        #     stop=None\n",
    "        # )\n",
    "        \n",
    "        print(response.choices[0].text)\n",
    "        text = response['choices'][0]['text']\n",
    "        usage = response[\"usage\"]\n",
    "\n",
    "        print(\"************************result********************************\")\n",
    "        print(text)\n",
    "        pprint(usage)\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(e) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = soup.text\n",
    "state = \"\"\n",
    "product = \"\"\n",
    "batch_size=3000\n",
    "tokens = 0\n",
    "for batch in range(0, len(html_text), batch_size):\n",
    "    batch = html_text[batch:batch+batch_size]\n",
    "    print(\"next batch...\")\n",
    "    # print(\"************************input text********************************\")\n",
    "    # print(batch)\n",
    "    prompt = f\"\"\"You are a website scrapper that is looking for the main product at that is presented in the html. Your job is to find all the details of a product from its html page. \n",
    "    I will stream you the html page with batchs of 1000 characters int the following json format:\n",
    "    {{\n",
    "        \"html\": <html batch>,\n",
    "        \"state\": <relevant information from previous batches that you need inorder to update the \"prodct\" details>,\n",
    "        \"product\" {{\n",
    "            \"product name\": \"<product name>\",\n",
    "            \"product anotations\": [\n",
    "                {{\n",
    "                    \"price\": <price as a number and currency mark, if not found, put -1>,\n",
    "                    \"size\": \"<size>\",\n",
    "                    \"color\": \"<color>\",\n",
    "                    etc...\n",
    "                }}\n",
    "            ]\n",
    "        }},\n",
    "        batch_size: 1000\n",
    "    }}\n",
    "    and you will return the the following json format:\n",
    "    {{\n",
    "        \"product\" {{\n",
    "            \"product name\": <product name>,\n",
    "            \"product anotations\": [\n",
    "                {{\n",
    "                    \"price\": <price>,\n",
    "                    \"size\": <size>,\n",
    "                    \"color\": <color>,\n",
    "                    etc...\n",
    "                }}\n",
    "            ]\n",
    "        }},\n",
    "        \"batch summary\": <summary of the batch, what it consists of>,\n",
    "        \"state\": <relevant information that you need to save from previous batches to complete the information about the product.>\n",
    "    }}\n",
    "\n",
    "    write only the json object string without any strings before or after the json string so it can be parsed by json library without any string before the first {{ and after the }} and dont write output: at the begining of the response.\n",
    "    \n",
    "    input batch for next iteration:\n",
    "    {{\n",
    "        \"html\": {batch},\n",
    "        \"state\": {state},\n",
    "        \"product\" {product},\n",
    "        batch_size: {batch_size}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(engine=\"davinchi-003\", prompt=prompt, max_tokens=1024, temperature=0)\n",
    "        # response = openai.ChatCompletion.create(\n",
    "        #     engine=\"gpt-35-turbo\",\n",
    "        #     messages = [\n",
    "        #             {\"role\": \"system\", \"content\": \"you are a website scrapper that is looking for products and prices in scripts in html. find the products and details about the products (sizes, colors, etc...) and price. when you find a product, create a dictionaries with the following format:\"},\n",
    "        #             {\"role\": \"user\", \"content\": script.text}\n",
    "        #         ],\n",
    "        #     temperature=0.7,\n",
    "        #     max_tokens=800,\n",
    "        #     top_p=0.95,\n",
    "        #     frequency_penalty=0,\n",
    "        #     presence_penalty=0,\n",
    "        #     stop=None\n",
    "        # )\n",
    "        \n",
    "        print(response['choices'][0]['text'])\n",
    "        json_response = json.loads(response['choices'][0]['text'])\n",
    "        state = json_response[\"state\"]\n",
    "        product = json_response[\"product\"]\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"state={state} product={product}\") \n",
    "        # input(\"press enter to continue\")\n",
    "        print(\"************************result********************************\")\n",
    "        pprint(usage)\n",
    "        tokens += usage[\"total_tokens\"]\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "result = f\"\"\"\n",
    "The product in the page is {product[\"product name\"]} and it has the following details:\n",
    "{product}\"\"\"\n",
    "pprint(result)\n",
    "print(f\"total tokens={tokens}.\\n\") \n",
    "\n",
    "price_turbo = tokens/1000*0.002\n",
    "print(f\"price={price_turbo}$/page for the turbo model\")\n",
    "# in the prints show the prices with only 2 digits after the decimal point.\n",
    "print(f\"price for 700,000,000 pages is {(price_turbo*700000000)/1000000:.2f}M$\")\n",
    "print(f\"price for 4,000,000,000 pages is {(price_turbo*4000000000)/1000000:.2f}M$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "966109304b06f24475972beef482557bb5471614be91d127d43959966e034004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
