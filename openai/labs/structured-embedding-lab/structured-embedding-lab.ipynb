{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import openai\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from num2words import num2words\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from transformers import GPT2TokenizerFast\n",
    "from pprint import pprint\n",
    "\n",
    "API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "RESOURCE_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2022-12-01\"\n",
    "print(openai.api_base)\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\"\n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    print(s)\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "print(glob(\"data/*.txt\"))\n",
    "# FAQ Example\n",
    "with open(\"data/openning bank account - FAQ.txt\", \"r\") as file:\n",
    "    doc = file.read()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "            {normalize_text(doc)}\n",
    "            Create a list of questions and answer based on the FAQ document above. \n",
    "            Create the output as a readable json format with the following format:\n",
    "            \n",
    "            [\n",
    "                {{\"<the question1>\":\"<the answer1>\"\\}}\n",
    "                {{\"<the question2>\":\"<the answer2>\"\\}}\n",
    "            ]\n",
    "            \"\"\"    \n",
    "response = openai.Completion.create(engine=\"davinchi-003\", prompt=prompt, max_tokens=1024)\n",
    "text = response['choices'][0]['text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(text)\n",
    "new_text = json.loads(text)\n",
    "\n",
    "pprint(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the input list of JSON objects\n",
    "json_list = []\n",
    "\n",
    "for l in new_text:\n",
    "    json_list.append([list(l.keys())[0], list(l.values())[0]])\n",
    "# Convert the list of JSON objects to a pandas dataframe\n",
    "df = pd.DataFrame(json_list)\n",
    "# Rename the columns of the dataframe\n",
    "df.columns = ['questions', 'answers']\n",
    "\n",
    "# Print the resulting dataframe\n",
    "\n",
    "df['curie_search_answers'] = df[\"answers\"].apply(lambda x : get_embedding(x, engine = 'embedding-model'))\n",
    "df['curie_search_questions'] = df[\"questions\"].apply(lambda x : get_embedding(x, engine = 'embedding-model'))\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(df, user_query, top_n=3, to_print=True):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        engine=\"embedding-model\"\n",
    "    )\n",
    "    # print(embedding)\n",
    "    df[\"similarities_answers\"] = df.curie_search_answers.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    df[\"similarities_questions\"] = df.curie_search_questions.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    \n",
    "    res = (\n",
    "        df.sort_values(\"similarities_answers\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def rephrase_answer(question, res, th_answers=0.8, th_questions=0.8):\n",
    "    answers = res[\"answers\"]\n",
    "    similarities_answers = res[\"similarities_answers\"]\n",
    "    similarities_questions = res[\"similarities_questions\"]\n",
    "    prompt = f\"\"\"\n",
    "            The user asked: {question}, and the answers are:\n",
    "            \"\"\"\n",
    "    answer_counter = 0\n",
    "    for k,v in answers.items():\n",
    "        if similarities_answers[k] > th_answers:\n",
    "            prompt += f\"\"\"\n",
    "            {v} \\n\n",
    "            \"\"\"\n",
    "            answer_counter += 1\n",
    "    \n",
    "    if answer_counter == 0:\n",
    "        print(\"no answer found to the question, looking for similar questions\")\n",
    "        for k,v in res[\"questions\"].items():\n",
    "            if similarities_questions[k] > th_questions:\n",
    "                prompt += f\"\"\"\n",
    "                {v}\n",
    "                \"\"\"\n",
    "                print(res[\"questions\"][k])\n",
    "                return res[\"answers\"][k]\n",
    "        return \"Sorry, I don't know the answer to that question.\"\n",
    "    \n",
    "    prompt += \"rephrase the answer to the question above.\"\n",
    "    print(f\"prompt={prompt}\")\n",
    "    response = openai.Completion.create(engine=\"davinchi-003\", prompt=prompt, max_tokens=400)\n",
    "    text = response['choices'][0]['text']\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"will it affect my credit\"\n",
    "res = search_docs(df, user_question, top_n=2)\n",
    "answer = rephrase_answer(user_question, res.to_dict())\n",
    "print(\"\")\n",
    "print(f\"question: {user_question}\")\n",
    "print(\"\")\n",
    "print(\"answer:\")\n",
    "print(\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Do you accept Quebec health card?\"\n",
    "res = search_docs(df, user_question, top_n=2)\n",
    "answer = rephrase_answer(user_question, res.to_dict())\n",
    "print(\"\")\n",
    "print(f\"question: {user_question}\")\n",
    "print(\"\")\n",
    "print(\"answer:\")\n",
    "print(\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Do you accept an israeli Driver licsnce?\"\n",
    "res = search_docs(df, user_question, top_n=2)\n",
    "answer = rephrase_answer(user_question, res.to_dict())\n",
    "print(\"\")\n",
    "print(f\"question: {user_question}\")\n",
    "print(\"\")\n",
    "print(\"answer:\")\n",
    "print(\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"When Ben Gurion were born?\"\n",
    "res = search_docs(df, user_question, top_n=2)\n",
    "answer = rephrase_answer(user_question, res.to_dict())\n",
    "print(\"\")\n",
    "print(f\"question: {user_question}\")\n",
    "print(\"\")\n",
    "print(\"answer:\")\n",
    "print(\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "966109304b06f24475972beef482557bb5471614be91d127d43959966e034004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
